{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credit:\n",
    "This work is heavily borrowed from the following source:\n",
    "Author: BARAN BINGÃ–L\n",
    "Kaggle URL: https://www.kaggle.com/code/baranbingl/face-shape-detection-85-acc-on-test-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install numpy matplotlib pillow torch torchvision scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import random\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as T\n",
    "from torch.cuda.amp import GradScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On device : cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "print(f\"On device : {device}\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_path = '../datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oval_training_path = os.path.join(datasets_path, 'training_set/Oval')\n",
    "# example_image_name = random.choice(os.listdir(oval_training_path))\n",
    "# example_image_path = os.path.join(oval_training_path, example_image_name)\n",
    "# example_image = Image.open(example_image_path)\n",
    "\n",
    "# plt.imshow(example_image)\n",
    "# plt.title(f\"Image Size: {example_image.size}\")\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomRotation(degrees=10),\n",
    "    T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transforms = T.Compose([\n",
    "    T.Resize((224, 224)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 24\n",
    "NUM_WORKERS = os.cpu_count() - 1\n",
    "TRAIN_PATH = os.path.join(datasets_path, './training_set')\n",
    "TEST_PATH = os.path.join(datasets_path, './testing_set')\n",
    "\n",
    "def safe_pil_loader(path):\n",
    "    try:\n",
    "        with open(path, 'rb') as f:\n",
    "            img = Image.open(f)\n",
    "            return img.convert('RGB')\n",
    "    except (OSError, SyntaxError):\n",
    "        return Image.new('RGB', (224, 224))\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=TRAIN_PATH, transform=train_transforms, loader=safe_pil_loader)\n",
    "test_dataset = datasets.ImageFolder(root=TEST_PATH, transform=test_transforms, loader=safe_pil_loader)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataiter = iter(train_loader)\n",
    "# images, labels = next(dataiter)\n",
    "\n",
    "# example_image = images[0]\n",
    "# example_image = example_image.permute(1, 2, 0).numpy()\n",
    "# example_label = labels[0].item()\n",
    "\n",
    "# mean = [0.485, 0.456, 0.406]\n",
    "# std = [0.229, 0.224, 0.225]\n",
    "# example_image = example_image * std + mean\n",
    "\n",
    "# plt.imshow(example_image)\n",
    "# plt.title(f\"Label: {example_label}\")\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lison/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/lison/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B4_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B4_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/home/lison/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "model = torchvision.models.efficientnet_b4(pretrained=True)\n",
    "num_classes = len(train_dataset.classes)\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.5, inplace=True),\n",
    "    nn.Linear(model.classifier[1].in_features, num_classes)\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, betas=(0.9, 0.999), weight_decay=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "\n",
    "model.to(device)\n",
    "num_epochs = 5\n",
    "best_val_loss = 1_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = GradScaler()\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train()\n",
    "#     train_losses =  []\n",
    "\n",
    "#     for inputs, labels in train_loader:\n",
    "\n",
    "#         inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         with torch.autocast(device_type=device, dtype=torch.float16):\n",
    "#           outputs = model(inputs)\n",
    "#           loss = criterion(outputs, labels)\n",
    "\n",
    "#         scaler.scale(loss).backward()\n",
    "\n",
    "#         scaler.step(optimizer)\n",
    "#         scaler.update()\n",
    "\n",
    "#         train_losses.append(loss.item())\n",
    "\n",
    "#     avg_train_loss = sum(train_losses) / len(train_losses)\n",
    "\n",
    "#     model.eval()\n",
    "#     validation_losses = []\n",
    "#     all_predictions = []\n",
    "#     all_labels = []\n",
    "\n",
    "#     with torch.inference_mode():\n",
    "#       for inputs, labels in test_loader:\n",
    "\n",
    "#         inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "#         outputs = model(inputs)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         validation_losses.append(loss)\n",
    "\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         all_predictions.extend(predicted.cpu().numpy())\n",
    "#         all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "#       avg_val_loss = sum(validation_losses) / len(validation_losses)\n",
    "#       scheduler.step(avg_val_loss)\n",
    "\n",
    "#       accuracy = accuracy_score(all_labels, all_predictions)\n",
    "#       print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "#       if avg_val_loss < best_val_loss:\n",
    "#         best_val_loss = avg_val_loss\n",
    "#         os.makedirs('models', exist_ok=True)\n",
    "#         torch.save(model.state_dict(), 'models/best_model.pth')\n",
    "# print(f'Best Validation Loss: {best_val_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, scheduler, device, num_epochs):\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "\n",
    "    if device.type == 'cuda':\n",
    "        scaler = GradScaler()\n",
    "        # print(\"Using Scaler\")\n",
    "    else:\n",
    "        scaler = None\n",
    "        # print(\"Not using Scaler\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_train_losses = []\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if scaler is not None:\n",
    "                # print(\"Using Scaler\")\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                # print(\"Not using Scaler\")\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            epoch_train_losses.append(loss.item())\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        avg_train_loss = np.mean(epoch_train_losses)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        train_accuracies.append(accuracy)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Train Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    # Plotting training loss and accuracy\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss')\n",
    "    plt.plot(range(1, num_epochs + 1), train_accuracies, label='Training Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Value')\n",
    "    plt.title('Training Loss and Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    test_losses = []\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_losses.append(loss.item())\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_test_loss = np.mean(test_losses)\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    precision = precision_score(all_labels, all_predictions, average='macro')\n",
    "    recall = recall_score(all_labels, all_predictions, average='macro')\n",
    "    f1 = f1_score(all_labels, all_predictions, average='macro')\n",
    "\n",
    "    print(f\"Test Loss: {avg_test_loss:.4f}, Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, save_path):\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "    torch.save(model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lison/.local/lib/python3.10/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Train Loss: 1.5775, Train Accuracy: 29.57%\n",
      "Epoch 2/5, Train Loss: 1.4208, Train Accuracy: 43.65%\n",
      "Epoch 3/5, Train Loss: 1.2528, Train Accuracy: 53.67%\n",
      "Epoch 4/5, Train Loss: 1.1089, Train Accuracy: 62.85%\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "# torch.cuda.memory_summary(device=device, abbreviated=False)\n",
    "train_model(model, train_loader, criterion, optimizer, scheduler, device, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(model, test_loader, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, '../outputs/best_model_self.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 uninstall -y numpy matplotlib pillow torch torchvision scikit-learn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
